{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f72e15e",
   "metadata": {},
   "source": [
    "## ML MODDEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20de49ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------\n",
    "# IMPORTS\n",
    "# ---------------------------------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from rouge_score import rouge_scorer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import networkx as nx\n",
    "import joblib\n",
    "\n",
    "# # Download NLTK data\n",
    "# nltk.download(\"punkt\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7ad7083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------\n",
    "# TEXT CLEANING FUNCTION\n",
    "# ---------------------------------------------------------\n",
    "import string\n",
    "def clean_text(text):\n",
    "\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "\n",
    "    # Remove HTML\n",
    "    text = re.sub(r\"<.*?>\", \" \", text)\n",
    "\n",
    "    # Remove URLs\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \" \", text)\n",
    "\n",
    "    # Remove emojis\n",
    "    text = re.sub(\n",
    "        \"[\" \n",
    "        u\"\\U0001F600-\\U0001F64F\"\n",
    "        u\"\\U0001F300-\\U0001F5FF\"\n",
    "        u\"\\U0001F680-\\U0001F6FF\"\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"\n",
    "        \"]+\", \n",
    "        \"\", \n",
    "        text\n",
    "    )\n",
    "\n",
    "    # Remove special symbols\n",
    "    text = re.sub(r\"[^a-zA-Z0-9\\s.,!?]\", \" \", text)\n",
    "\n",
    "    # Keep only allowed characters\n",
    "    allowed = set(string.ascii_letters + string.digits + \" .,!?\")\n",
    "    text = \"\".join(ch for ch in text if ch in allowed)\n",
    "\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Normalize whitespace\n",
    "    text = \" \".join(text.split())\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9fd4f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------\n",
    "# LOAD DATA\n",
    "# ---------------------------------------------------------\n",
    "df = pd.read_csv(\"../data/news.tsv\", sep=\"\\t\")\n",
    "\n",
    "df[\"text\"] = df[\"Headline\"].fillna(\"\") + \" \" + df[\"News body\"].fillna(\"\")\n",
    "df = df.rename(columns={\"Category\": \"label\"}).dropna()\n",
    "\n",
    "# Clean text\n",
    "df[\"clean_text\"] = df[\"text\"].apply(clean_text)\n",
    "\n",
    "# This is required for evaluation\n",
    "df[\"full_text\"] = df[\"text\"]   # FIXED\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "280c25f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The ideal landing spots for the top 30 NBA free agents The madness of NBA free agency is almost upon us. Scores of free agents, hundreds of millions in cap space and no clear title favorite means that it should be an energetic evening when free agency officially opens on June 30. But where are the top free agents headed? Only God and Woj know such things, but we\\'ll present our best arguments for the top 30. It\\'s not a prediction of where the players end up but rather a determination of where they deserve to end up when the music stops and the mad dash for chairs is over. The madness of NBA free agency is almost upon us. Scores of free agents, hundreds of millions in cap space and no clear title favorite means that it should be an energetic evening when free agency officially opens on June 30. But where are the top free agents headed? Only God and Woj know such things, but we\\'ll present our best arguments for the top 30. It\\'s not a prediction of where the players end up but rather a determination of where they deserve to end up when the music stops and the mad dash for chairs is over. Kawhi Leonard - Toronto Raptors Kawhi Leonard loves Southern California. He grew up in the Inland Empire, played his college ball at San Diego State and recently bought a huge house in Rancho Santa Fe. That\\'s a fine place for him to go in the offseason, but he owes it to himself and the Raptors to return and defend their first NBA title, even if it\\'s on a short-term deal. It\\'s hard to imagine a more ideal situation than he had in Toronto, unless it were 20 degrees warmer in the winter and Drake wasn\\'t allowed to grope the coaches . Kevin Durant - New York Knicks Kevin Durant was already unlikely to re-sign with the Warriors even before his Achilles injury. But after the team medical staff controversially cleared him to return in the Finals, and Klay Thompson tore his own ACL, the Warriors dynasty is on hiatus, if not canceled entirely. It\\'s the perfect time for KD to get his own team in New York, join up with R.J. Barrett and Mitchell Robinson and let the Knicks use their bounty of cap space and draft picks to build around him. Durant should demand every concession possible from the desperate Knicks   agent Rich Kleiman as team president, season tickets for Charles Oakley, a role in Spike Lee\\'s next film and a ban on James Dolan playing guitar on the team plane. Kyrie Irving - Brooklyn Nets Point guard/ philosopher Kyrie Irving reportedly \"didn\\'t like living in Boston,\" and the \"worst-kept secret of the summer\" is that he\\'s headed for the Brooklyn Nets. It makes sense. Irving grew up a Nets fan. The Nets offensive philosophy involves shooting as many threes as possible, and Kyrie loves that. And considering how Kyrie feels about the curvature of the earth, it\\'s fitting that he\\'d play at the Barclays Center, at the intersection of Atlantic and FLATbush Avenues. Klay Thompson - Golden State Warriors The Warriors might break up their championship team this summer, but it\\'s hard to imagine they\\'d break up the Splash Brothers. Expect Klay Thompson to re-up for five more years of toasters , scoring explosions , ridiculous postgame comments , Bergmanesque commercials , and man-on-the-street interviews about scaffolding. Jimmy Butler - Los Angeles Lakers Jimmy Butler wants to be a star, he wants to play for a winner and as shown by his time in Minnesota, he dislikes young players . That\\'s perfect for the Lakers, who are in the process of getting rid of all the young players on their roster, save Kyle Kuzma. And while Karl-Anthony Towns and Andrew Wiggins might stay up all night playing video games , LeBron James is so devoted to rest that he sleeps through his own holiday parties . Kemba Walker - Charlotte Hornets Though it\\'s unlikely that Michael Jordan will pay Kemba Walker the supermax contract he earned by making the All-NBA team, Walker says he\\'s willing to take less to stay in Charlotte. The Hornets can give Walker more dollars and years than any other team, and if they don\\'t bring back their all-time leading scorer, it\\'s not clear who\\'s left for the fans to watch   Nic Batum? Marvin Williams? Kemba should get paid and have his jersey retired in the Queen City. Kristaps Porzingis - Dallas Mavericks The Mavericks traded a former lottery pick and two future first round picks to get Kristaps Porzingis from the Knicks and took on the bad contracts of Courtney Lee and Tim Hardaway, Jr. in the process. There\\'s no way they aren\\'t matching any and all offers for restricted free agent Porzingis, no matter that he\\'s missed more than a full season and no matter what happens regarding his legal troubles . After all, that fits in seamlessly with the Mavericks\\' workplace culture . Khris Middleton - Milwaukee Bucks When Milwaukee traded the No. 30 pick in the draft to dump Tony Snell\\'s contract, it was a clear sign they\\'re trying to retain all of their biggest free agents. Middleton\\'s relatively low cap hold means the Bucks can sign other free agents   perhaps starting center Brook Lopez   before locking up Middleton to what should be close to a max deal. But how could they let Middleton walk when he was Giannis\\' first pick among the reserves in the All-Star draft? Tobias Harris - Brooklyn Nets Tobias Harris is a good NBA player who\\'s been treated as an afterthought his whole career. He was traded on draft night, after being traded as a future pick twice before, then Orlando and Milwaukee each dumped him for very little. Harris was having the best year of his career for the Clippers last year, at which point they traded him to Philadelphia. If he excelled on the little brother team in Los Angeles, why wouldn\\'t perpetual second choice Tobias Harris also thrive with New York City\\'s junior franchise? Brooklyn has a gaping hole at power forward, and Harris is an ideal stretch four to pair with Jarrett Allen   that is, until he\\'s unceremoniously traded again two years into this contract. DeMarcus Cousins - Dallas Mavericks Though Boogie Cousins strongly considered signing with Boston last summer, Bill Simmons\\' dream of Cousins in Celtics green probably died when a fan allegedly called Boogie a racial epithet last season. Instead, Cousins will end up with the team that openly coveted Dwight Howard and DeAndre Jordan for years and is likely to strike out with its top free agent targets. Cousins will be a good frontcourt partner to Porzingis and an assist magnet for Luka Doncic, and he can bond with Mark Cuban about arguing with the refs. And it doesn\\'t matter that Cousins may have lost a step because Rick Carlisle doesn\\'t want his team to play fast anyway. D\\'Angelo Russell - Minnesota Timberwolves The Nets want Kyrie Irving, and Karl-Anthony Towns wants to play with his good friend D\\'Angelo Russell. And while the Wolves don\\'t have the cap space to sign Russell outright, if they can find a third team to take Jeff Teague (with a pick attached as incentive), they can get Russell on a sign-and-trade. It\\'ll be like Stephon Marbury and Kevin Garnett all over again, only without the resentment or interior defense. Al Horford - Los Angeles Clippers Al Horford clearly has a long-term offer, since he opted out of $30 million for next year and broke off negotiations with Boston. Odds are that team is the Los Angeles Clippers, which can play Horford at either power forward or center, providing much-needed shooting and defense. Plus, although Doc Rivers is no longer the GM, he fits the Doc free agent ideal: a guy who was an Eastern Conference All-Star 10 years ago. Marc Gasol - New Orleans Pelicans Marc Gasol has until June 27 to decide on his 2019-20 option, but for the purposes of this exercise, let\\'s assume he opts out to get a long-term deal. And after so many great years in Memphis, Gasol should go further down the mighty Mississippi and team up with Zion Williamson in New Orleans. He can teach Zion the principles of grit and grind from his Grizzlies days and empathize with Lonzo Ball, Brandon Ingram and Josh Hart about what it\\'s like to get traded away from the Lakers for a star big man. And like New Orleans itself from 1763-1803, Gasol used to belong to Spain. Brook Lopez - Orlando Magic Brook Lopez had an incredible season for the Bucks last year, who provided a showcase for \"Splash Mountain\" on the national stage during the playoffs. The Bucks can give Lopez up to $14 million next year and a real chance at a title, but they can\\'t give Brook what he truly craves: proximity to theme parks, which is why Orlando is such a perfect fit, given that Brook already has a house on the grounds of Disney World. He\\'s a better fit for Orlando\\'s offense than its incumbent free-agent center, Nikola Vucevic, and he knows way more Disney trivia. Malcolm Brogdon - Phoenix Suns Do the Bucks want to bring back Malcolm Brodgon this summer? Of course. But after signing Eric Bledsoe to a $70 million extension, are they willing to pay two point guards big money? The Suns coveted Brodgon back when they traded Bledsoe to Milwaukee two years ago, and now they can steal him with an offer large enough to make Milwaukee flinch. And as evidenced by its selection of Cameron Johnson, Phoenix loves guys who turn 24 during their rookie year, not to mention point guards who get hurt a lot. Julius Randle - New York Knicks This is the biggest free-agency period for the Knicks since 2010 when they cleared their books to make room to sign LeBron James. When he rejected them, the Knicks spent their money on Amar\\'e Stoudemire, a dynamic athletic forward with a history of leg injuries who played no defense at all. The closest thing in this free-agent class is Julius Randle, who is at least younger and healthier than Stoudemire was in 2010. Nikola Vucevic - Sacramento Kings Willie Cauley-Stein doesn\\'t want to return to the Kings . While the Kings have solid young big man prospects in Harry Giles and Marvin Bagley III, they could use a veteran presence in the middle, especially one who can shoot like Vucevic. After all, Vucevic is a highly skilled big man from Montenegro, and Kings GM Vlade Divac is a highly skilled big man from neighboring Serbia   and Vucevic has spent his entire career in Orlando, which makes Sacramento look like a cultural mecca. Nikola Mirotic - Indiana Pacers Mirotic is a tall white guy who knocks down threes and rebounds. He\\'d be perfect for the Pacers even if they didn\\'t have four different forwards entering free agency this summer. Three-point shooting is probably Indiana\\'s greatest need, so who better than the Montenegrin Troy Murphy? After all, neither Mirotic or the Pacers could hit a shot in the playoffs this year. Harrison Barnes - Philadelphia 76ers He may not be Philadelphia\\'s top target, but if Harris and/or Butler leave, Harrison Barnes may be the best possible consolation prize for the 76ers. He can play both forward spots and shoots threes better than than both Harris and Butler. With Ben Simmons dating celebrities and Joel Embiid hitting on pop stars on Twitter, the Sixers could use a thoughtful young man like Barnes who married his college sweetheart and has the NBA\\'s dorkiest nickname: \"The Black Falcon.\" Markieff and Marcus Morris - Denver Nuggets The Morris twins once negotiated their contracts together in Phoenix, and they should be allowed to sign as a tandem this summer as well. Why not split a mid-level exception in Denver, serving as an identical pair of backup forwards, intimidating and confusing opponents in equal measure? J. J. Redick - Philadelphia 76ers Yes, Redick will get offers from all over the league, but he\\'s got to make his decision based on what\\'s most important to him: p odcasting . He might have left the 76ers, but leaving his podcast studio, with the microphones set up just the way he likes it, would be too much to bear. Expect another one-year deal in Philly, unless he gets a max offer from NPR. George Hill - Indiana Pacers Milwaukee is expected to waive George Hill and his $19M salary for next year. If so, his old team could use a veteran point guard, in the same city where he played his college ball and he still runs his charitable organization, George Hill Rising Stars . Hill can mentor Aaron Holiday, knock down threes and delight all the IUPUI fans in the crowd. Thaddeus Young - Chicago Bulls The Bulls have a pair of promising young bigs in Wendell Carter and Lauri Markkanen, but behind those two and Otto Porter, they have little in the way of backups. Thaddeus Young is a perfect addition to their bench. He\\'s well-rounded, plays both forward spots, locks down on defense and doesn\\'t need plays called for him. That his signing would weaken division rival Indiana is just an added bonus. Rudy Gay - Golden State Warriors If you lose Kevin Durant and have limited resources to replace him, his old friend Rudy Gay is the best discount KD on the market. He even has his own Achilles tear! The Warriors can use Gay\\'s scoring, especially if he can keep up his hot three-point shooting from last year. Bojan Bogdanovic - Sacramento Kings The Kings have a chance to pair Bojan Bogdanovic and Bogdan Bogdanovic on one roster. It\\'s worth it just to see what the back of their jerseys look like. BOG and BOJ? If he doesn\\'t sign him, Vlade Divac should at least trade Bogdan to wherever Bojan does end up. DeAndre Jordan - Houston Rockets There are rumors that Kevin Durant suitors are trying to sign his friend DeAndre Jordan as a recruitment effort, but there\\'s another superstar friend who needs DeAndre badly. That\\'s Chris Paul with the Rockets. If Clint Capela gets traded , the Rockets need a dunker in the middle, but even if he stays, Chris Paul\\'s feud with James Harden means he needs a new co-star for his State Farm commercials. DeAndre has experience destroying Paul\\'s cursed homes , and this time CP3 won\\'t make him wear a dress . Danny Green - wherever Kawhi goes Danny Green and Kawhi Leonard have been teammates for Kawhi\\'s entire career and most of Green\\'s. Green is a perfect complement to Kawhi on the wing, draining threes, playing hard defense and rebooting his operating system when it freezes. They\\'re not even exactly friends...just perfect co-workers: Danny Green is loquacious; Kawhi is silent. Danny catches and shoots; Kawhi dribbles and drives. Green slaps passes away; Kawhi snatches them in his massive hands. They should both stay in Toronto, but if Kawhi goes he shouldn\\'t leave Danny behind. Ricky Rubio - Orlando Magic D.J. Augustin had his moments, but the Magic could use a reliable point guard who can stop the ball at the point of attack. That\\'s Ricky Rubio, who may not shoot well, but he can run an offense and get the ball to Orlando\\'s army of long-armed bigs. Plus, Rubio, the happiest boy in the NBA , deserves to finally play somewhere sunny and warm. Jonas Valanciunas - Memphis Grizzlies Jonas Valanciunas put up the best numbers of his career after coming to Memphis in the Marc Gasol trade, averaging 19.9 points and 10.7 rebounds. He opted out of his player option to negotiate a longer deal with Memphis, which sounds like a splendid idea for everyone involved. JV is still only 27, so there\\'s not a ton of risk on the back end of his contract, and he\\'ll let Jaren Jackson, Jr. play more power forward minutes until he gets bigger and stronger. Paul Millsap - Denver Nuggets (AKA \"Streetball Paul\") Paul Millsap has a $30 million team option for next season, but he shouldn\\'t really be on this list because Denver should just pick it up. The only reason to decline the option would be to re-sign Millsap to a longer, cheaper deal. But why mess around? The Nuggets don\\'t have the cap space to sign a significant free agent anyway, and they\\'re still $10 million under the luxury tax line.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'][12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99bc9ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------\n",
    "# TEXT RANK SUMMARIZER\n",
    "# ---------------------------------------------------------\n",
    "def textrank_summarize(text, top_n=3):\n",
    "    cleaned = clean_text(text)\n",
    "    sentences = sent_tokenize(cleaned)\n",
    "\n",
    "    if len(sentences) <= top_n:\n",
    "        return \" \".join(sentences)\n",
    "\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    vectors = vectorizer.fit_transform(sentences).toarray()\n",
    "\n",
    "    sim_matrix = cosine_similarity(vectors)\n",
    "\n",
    "    nx_graph = nx.from_numpy_array(sim_matrix)\n",
    "    scores = nx.pagerank(nx_graph)\n",
    "\n",
    "    ranked = sorted(((scores[i], s) for i, s in enumerate(sentences)), reverse=True)\n",
    "    summary = \" \".join([s for _, s in ranked[:top_n]])\n",
    "\n",
    "    return summary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1dd0c871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------\n",
    "# TF-IDF SENTENCE SCORING\n",
    "# ---------------------------------------------------------\n",
    "def tfidf_summarize(text, top_n=3):\n",
    "    cleaned = clean_text(text)\n",
    "    sentences = sent_tokenize(cleaned)\n",
    "\n",
    "    if len(sentences) <= top_n:\n",
    "        return \" \".join(sentences)\n",
    "\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform(sentences)\n",
    "\n",
    "    scores = tfidf_matrix.mean(axis=1).A.flatten()\n",
    "\n",
    "    ranked_idx = np.argsort(scores)[::-1]\n",
    "    selected = [sentences[i] for i in ranked_idx[:top_n]]\n",
    "\n",
    "    return \" \".join(selected)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# REFERENCE SUMMARY (WEAK BASELINE)\n",
    "# ---------------------------------------------------------\n",
    "def reference_summary(text):\n",
    "    sents = sent_tokenize(clean_text(text))\n",
    "    return \" \".join(sents[:2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d969eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------\n",
    "# ROUGE EVALUATION\n",
    "# ---------------------------------------------------------\n",
    "scorer = rouge_scorer.RougeScorer([\"rouge1\", \"rouge2\", \"rougeL\"], use_stemmer=True)\n",
    "\n",
    "def evaluate_model(summarizer_fn, df, samples=50):\n",
    "\n",
    "    rouge1_scores, rouge2_scores, rougeL_scores = [], [], []\n",
    "\n",
    "    for i in range(min(samples, len(df))):\n",
    "\n",
    "        text = df.iloc[i][\"full_text\"]\n",
    "        ref = reference_summary(text)\n",
    "        pred = summarizer_fn(text)\n",
    "\n",
    "        scores = scorer.score(ref, pred)\n",
    "\n",
    "        rouge1_scores.append(scores[\"rouge1\"].fmeasure)\n",
    "        rouge2_scores.append(scores[\"rouge2\"].fmeasure)\n",
    "        rougeL_scores.append(scores[\"rougeL\"].fmeasure)\n",
    "\n",
    "    return {\n",
    "        \"rouge1\": np.mean(rouge1_scores),\n",
    "        \"rouge2\": np.mean(rouge2_scores),\n",
    "        \"rougeL\": np.mean(rougeL_scores),\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6dbf5ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating TextRank...\n",
      "Evaluating TF-IDF...\n",
      "\n",
      "Evaluation Completed.\n",
      "Saved to: rouge_eval_results.csv\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# RUN EVALUATION\n",
    "# ---------------------------------------------------------\n",
    "print(\"Evaluating TextRank...\")\n",
    "textrank_scores = evaluate_model(textrank_summarize, df)\n",
    "\n",
    "print(\"Evaluating TF-IDF...\")\n",
    "tfidf_scores = evaluate_model(tfidf_summarize, df)\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# SAVE RESULTS TO CSV\n",
    "# ---------------------------------------------------------\n",
    "OUTPUT_CSV = \"rouge_eval_results.csv\"  # change if needed\n",
    "\n",
    "new_results = pd.DataFrame([\n",
    "    {\n",
    "        \"Model\": \"TextRank\",\n",
    "        \"rouge1\": textrank_scores[\"rouge1\"],\n",
    "        \"rouge2\": textrank_scores[\"rouge2\"],\n",
    "        \"rougeL\": textrank_scores[\"rougeL\"],\n",
    "        \"rougeLsum\": textrank_scores[\"rougeL\"],\n",
    "        \"Average Score\": np.mean([\n",
    "            textrank_scores[\"rouge1\"],\n",
    "            textrank_scores[\"rouge2\"],\n",
    "            textrank_scores[\"rougeL\"],\n",
    "        ])\n",
    "    },\n",
    "    {\n",
    "        \"Model\": \"TF-IDF\",\n",
    "        \"rouge1\": tfidf_scores[\"rouge1\"],\n",
    "        \"rouge2\": tfidf_scores[\"rouge2\"],\n",
    "        \"rougeL\": tfidf_scores[\"rougeL\"],\n",
    "        \"rougeLsum\": tfidf_scores[\"rougeL\"],\n",
    "        \"Average Score\": np.mean([\n",
    "            tfidf_scores[\"rouge1\"],\n",
    "            tfidf_scores[\"rouge2\"],\n",
    "            tfidf_scores[\"rougeL\"],\n",
    "        ])\n",
    "    }\n",
    "])\n",
    "\n",
    "new_results = new_results.round(4)\n",
    "\n",
    "# If CSV exists → append, else create new\n",
    "try:\n",
    "    old_df = pd.read_csv(OUTPUT_CSV)\n",
    "    final_df = pd.concat([old_df, new_results], ignore_index=True)\n",
    "except FileNotFoundError:\n",
    "    final_df = new_results\n",
    "\n",
    "final_df.to_csv(OUTPUT_CSV, index=False)\n",
    "\n",
    "print(\"\\nEvaluation Completed.\\nSaved to:\", OUTPUT_CSV)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88dfefa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "      <th>Average Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bert</td>\n",
       "      <td>0.748193</td>\n",
       "      <td>0.686271</td>\n",
       "      <td>0.688875</td>\n",
       "      <td>0.688424</td>\n",
       "      <td>0.7077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lstm_bahdanau</td>\n",
       "      <td>0.685955</td>\n",
       "      <td>0.300094</td>\n",
       "      <td>0.513951</td>\n",
       "      <td>0.225389</td>\n",
       "      <td>0.5433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TextRank</td>\n",
       "      <td>0.502800</td>\n",
       "      <td>0.392400</td>\n",
       "      <td>0.440200</td>\n",
       "      <td>0.440200</td>\n",
       "      <td>0.4451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>0.483600</td>\n",
       "      <td>0.377900</td>\n",
       "      <td>0.414400</td>\n",
       "      <td>0.414400</td>\n",
       "      <td>0.4253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model    rouge1    rouge2    rougeL  rougeLsum  Average Score\n",
       "0           bert  0.748193  0.686271  0.688875   0.688424         0.7077\n",
       "1  lstm_bahdanau  0.685955  0.300094  0.513951   0.225389         0.5433\n",
       "2       TextRank  0.502800  0.392400  0.440200   0.440200         0.4451\n",
       "3         TF-IDF  0.483600  0.377900  0.414400   0.414400         0.4253"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df1=pd.read_csv(\"../rouge_eval_results.csv\")\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0a85c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pereira is also an international, and if de boer wants to include ezequiel barco on the bench, he will need to shed one of his internationals from the last squad. well, aside from the obvious, we still don t have a ton of data points from frank de boer in how he prefers to rotate his team for let s be honest an inferior competition. with three internationals in the starting lineup, i think eric remedi and ezequiel barco will round out the five maximum allowed.\n"
     ]
    }
   ],
   "source": [
    "sample_text = df['full_text'][0]\n",
    "sam = textrank_summarize(sample_text)\n",
    "print(sam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4fd7921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved summarizer functions → ../Summarization/summarizer_functions.py\n"
     ]
    }
   ],
   "source": [
    "best_model = {\n",
    "    \"name\": best_model_name,\n",
    "    \"top_n\": 3\n",
    "}\n",
    "\n",
    "import joblib\n",
    "joblib.dump(best_model, f\"../Summarization/best_summarizer_{best_model_name}.pkl\")\n",
    "\n",
    "summarizer_code = \"\"\"\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import networkx as nx\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# CLEANING FUNCTION\n",
    "# ---------------------------------------------------------\n",
    "def clean_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    text = re.sub(r\"<.*?>\", \" \", text)\n",
    "    text = re.sub(r\"http\\\\S+|www\\\\S+|https\\\\S+\", \" \", text)\n",
    "    text = re.sub(\"[\" \n",
    "                  u\"\\\\U0001F600-\\\\U0001F64F\"\n",
    "                  u\"\\\\U0001F300-\\\\U0001F5FF\"\n",
    "                  u\"\\\\U0001F680-\\\\U0001F6FF\"\n",
    "                  u\"\\\\U0001F1E0-\\\\U0001F1FF\"\n",
    "                  \"]+\", \"\", text)\n",
    "    text = re.sub(r\"[^a-zA-Z0-9\\\\s.,!?]\", \" \", text)\n",
    "    text = text.lower()\n",
    "    text = \" \".join(text.split())\n",
    "    return text\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# TEXT RANK SUMMARY\n",
    "# ---------------------------------------------------------\n",
    "def textrank_summarize(text, top_n=3):\n",
    "    cleaned = clean_text(text)\n",
    "    sentences = sent_tokenize(cleaned)\n",
    "    if len(sentences) <= top_n:\n",
    "        return \" \".join(sentences)\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    vectors = vectorizer.fit_transform(sentences).toarray()\n",
    "    sim_matrix = cosine_similarity(vectors)\n",
    "    nx_graph = nx.from_numpy_array(sim_matrix)\n",
    "    scores = nx.pagerank(nx_graph)\n",
    "    ranked = sorted(((scores[i], s) for i, s in enumerate(sentences)), reverse=True)\n",
    "    return \" \".join([s for _, s in ranked[:top_n]])\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# TF-IDF SCORING SUMMARY\n",
    "# ---------------------------------------------------------\n",
    "def tfidf_summarize(text, top_n=3):\n",
    "    cleaned = clean_text(text)\n",
    "    sentences = sent_tokenize(cleaned)\n",
    "    if len(sentences) <= top_n:\n",
    "        return \" \".join(sentences)\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform(sentences)\n",
    "    scores = tfidf_matrix.mean(axis=1).A.flatten()\n",
    "    ranked_idx = scores.argsort()[::-1]\n",
    "    selected = [sentences[i] for i in ranked_idx[:top_n]]\n",
    "    return \" \".join(selected)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# UNIFIED SUMMARIZER FUNCTION\n",
    "# ---------------------------------------------------------\n",
    "def summarize(text, model_name, top_n=3):\n",
    "    if model_name == \"TextRank\":\n",
    "        return textrank_summarize(text, top_n)\n",
    "    elif model_name == \"TF-IDF\":\n",
    "        return tfidf_summarize(text, top_n)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown summarization model: \" + model_name)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "with open(\"summarizer_functions.py\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(summarizer_code)\n",
    "\n",
    "print(\"Saved summarizer functions → ../Summarization/summarizer_functions.py\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3eb89cd",
   "metadata": {},
   "source": [
    "#### DL Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2cff4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re, string\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e133427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------\n",
    "# TEXT CLEANING FUNCTION\n",
    "# ---------------------------------------------------------\n",
    "def clean_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "\n",
    "    text = re.sub(r\"<.*?>\", \" \", text)                      # Remove HTML\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \" \", text)   # Remove URLs\n",
    "\n",
    "    # Remove emojis\n",
    "    text = re.sub(\"[\" \n",
    "                  u\"\\U0001F600-\\U0001F64F\"\n",
    "                  u\"\\U0001F300-\\U0001F5FF\"\n",
    "                  u\"\\U0001F680-\\U0001F6FF\"\n",
    "                  u\"\\U0001F1E0-\\U0001F1FF\"\n",
    "                  \"]+\", \"\", text)\n",
    "\n",
    "    text = re.sub(r\"[^a-zA-Z0-9\\s.,!?]\", \" \", text)        # Special chars\n",
    "    allowed = set(string.ascii_letters + string.digits + \" .,!?\")\n",
    "    text = \"\".join(ch for ch in text if ch in allowed)\n",
    "\n",
    "    text = text.lower()\n",
    "    text = \" \".join(text.split())\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2a22ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------\n",
    "# LOAD DATA (PENS)\n",
    "# ---------------------------------------------------------\n",
    "df = pd.read_csv(\"../data/news.tsv\", sep=\"\\t\")\n",
    "\n",
    "df[\"article\"] = df[\"News body\"].fillna(\"\").apply(clean_text)\n",
    "df[\"summary\"] = df[\"Headline\"].fillna(\"\").apply(clean_text)\n",
    "\n",
    "df = df[(df[\"article\"].str.len() > 0) & (df[\"summary\"].str.len() > 0)]\n",
    "\n",
    "# Add special tokens\n",
    "df[\"summary_in\"]  = \"<sos> \" + df[\"summary\"]\n",
    "df[\"summary_out\"] = df[\"summary\"] + \" <eos>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c4f3280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------\n",
    "# TOKENIZATION\n",
    "# ---------------------------------------------------------\n",
    "MAX_ART_LEN = 400\n",
    "MAX_SUM_LEN = 30\n",
    "SRC_VOCAB = 20000\n",
    "TGT_VOCAB = 10000\n",
    "\n",
    "src_tok = Tokenizer(num_words=SRC_VOCAB, oov_token=\"<unk>\", filters=\"\")\n",
    "src_tok.fit_on_texts(df[\"article\"])\n",
    "\n",
    "tgt_tok = Tokenizer(num_words=TGT_VOCAB, oov_token=\"<unk>\")\n",
    "tgt_tok.fit_on_texts(df[\"summary_in\"].tolist() + df[\"summary_out\"].tolist())\n",
    "\n",
    "# Convert to sequences\n",
    "enc_seq = pad_sequences(\n",
    "    src_tok.texts_to_sequences(df[\"article\"]),\n",
    "    maxlen=MAX_ART_LEN,\n",
    "    padding=\"post\",\n",
    "    truncating=\"post\"\n",
    ")\n",
    "\n",
    "dec_in_seq = pad_sequences(\n",
    "    tgt_tok.texts_to_sequences(df[\"summary_in\"]),\n",
    "    maxlen=MAX_SUM_LEN,\n",
    "    padding=\"post\",\n",
    "    truncating=\"post\"\n",
    ")\n",
    "\n",
    "dec_out_seq = pad_sequences(\n",
    "    tgt_tok.texts_to_sequences(df[\"summary_out\"]),\n",
    "    maxlen=MAX_SUM_LEN,\n",
    "    padding=\"post\",\n",
    "    truncating=\"post\"\n",
    ")\n",
    "\n",
    "src_vocab = min(SRC_VOCAB, len(src_tok.word_index)+1)\n",
    "tgt_vocab = min(TGT_VOCAB, len(tgt_tok.word_index)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9a5ae37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tgt_tokenizer.pkl']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(src_tok, \"src_tokenizer.pkl\")\n",
    "joblib.dump(tgt_tok, \"tgt_tokenizer.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc652369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------\n",
    "# CALLBACKS\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "\n",
    "from tensorflow.keras.callbacks import (\n",
    "    EarlyStopping,\n",
    "    ReduceLROnPlateau,\n",
    "    ModelCheckpoint\n",
    ")\n",
    "early_stop = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=3,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    factor=0.5,\n",
    "    patience=2,\n",
    "    min_lr=1e-5,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "ckpt_lstm = ModelCheckpoint(\n",
    "    \"../Summarization/lstm_best_model.h5\",\n",
    "    monitor=\"val_loss\",\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "ckpt_gru = ModelCheckpoint(\n",
    "    \"../Summarization/gru_best_model.h5\",\n",
    "    monitor=\"val_loss\",\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Optimizer\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "optimizer = Adam(\n",
    "    learning_rate=0.001,\n",
    "    clipnorm=1.0   # protects against exploding gradients\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5f5cdb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMB_DIM = 96          # was 128 (faster)\n",
    "LATENT_DIM = 192     # was 256 (faster)\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fb489da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,920,000</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">960,000</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)         │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>,      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">221,952</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │ not_equal[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)]             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>), │    <span style=\"color: #00af00; text-decoration-color: #00af00\">221,952</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>),      │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],       │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)]      │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]        │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ attention           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)         │                   │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ attention[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10000</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,850,000</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m96\u001b[0m)   │  \u001b[38;5;34m1,920,000\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m96\u001b[0m)    │    \u001b[38;5;34m960,000\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)         │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m,      │    \u001b[38;5;34m221,952\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                     │ \u001b[38;5;34m192\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │ not_equal[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│                     │ \u001b[38;5;34m192\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n",
       "│                     │ \u001b[38;5;34m192\u001b[0m)]             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m192\u001b[0m), │    \u001b[38;5;34m221,952\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m),      │            │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],       │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m)]      │            │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]        │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ attention           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m192\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│ (\u001b[38;5;33mAttention\u001b[0m)         │                   │            │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m384\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ attention[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m10000\u001b[0m) │  \u001b[38;5;34m3,850,000\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,173,904</span> (27.37 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,173,904\u001b[0m (27.37 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,173,904</span> (27.37 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,173,904\u001b[0m (27.37 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# LSTM MODEL\n",
    "# ---------------------------------------------------------\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Attention, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "\n",
    "# ----- Encoder -----\n",
    "encoder_inputs = Input(shape=(MAX_ART_LEN,))\n",
    "enc_emb = Embedding(src_vocab, EMB_DIM, mask_zero=True)(encoder_inputs)\n",
    "\n",
    "encoder_lstm = LSTM(LATENT_DIM, return_sequences=True, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
    "\n",
    "# ----- Decoder -----\n",
    "decoder_inputs = Input(shape=(MAX_SUM_LEN,))\n",
    "dec_emb = Embedding(tgt_vocab, EMB_DIM, mask_zero=True)(decoder_inputs)\n",
    "\n",
    "decoder_lstm = LSTM(LATENT_DIM, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=[state_h, state_c])\n",
    "\n",
    "# ----- Attention -----\n",
    "attn = Attention()\n",
    "attn_out = attn([decoder_outputs, encoder_outputs])\n",
    "\n",
    "decoder_concat = Concatenate(axis=-1)([decoder_outputs, attn_out])\n",
    "\n",
    "# ----- Output -----\n",
    "decoder_dense = Dense(tgt_vocab, activation=\"softmax\")\n",
    "outputs = decoder_dense(decoder_concat)\n",
    "\n",
    "# ----- Final Model -----\n",
    "lstm_model = Model([encoder_inputs, decoder_inputs], outputs)\n",
    "\n",
    "lstm_model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3369a14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,920,000</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">960,000</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)           │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>,      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">167,040</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │ not_equal[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)]             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gru_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)         │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>), │    <span style=\"color: #00af00; text-decoration-color: #00af00\">167,040</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)]      │            │ gru[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>]         │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ attention_1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ gru_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)         │                   │            │ gru[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ gru_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ attention_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10000</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,850,000</span> │ concatenate_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m96\u001b[0m)   │  \u001b[38;5;34m1,920,000\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m96\u001b[0m)    │    \u001b[38;5;34m960,000\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gru (\u001b[38;5;33mGRU\u001b[0m)           │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m,      │    \u001b[38;5;34m167,040\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                     │ \u001b[38;5;34m192\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │ not_equal[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│                     │ \u001b[38;5;34m192\u001b[0m)]             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gru_1 (\u001b[38;5;33mGRU\u001b[0m)         │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m192\u001b[0m), │    \u001b[38;5;34m167,040\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m)]      │            │ gru[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m]         │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ attention_1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m192\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ gru_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
       "│ (\u001b[38;5;33mAttention\u001b[0m)         │                   │            │ gru[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_2       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m384\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ gru_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ attention_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m10000\u001b[0m) │  \u001b[38;5;34m3,850,000\u001b[0m │ concatenate_2[\u001b[38;5;34m0\u001b[0m]… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,064,080</span> (26.95 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,064,080\u001b[0m (26.95 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,064,080</span> (26.95 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,064,080\u001b[0m (26.95 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# GRU MODEL\n",
    "# ---------------------------------------------------------\n",
    "from tensorflow.keras.layers import GRU\n",
    "\n",
    "# ----- Encoder -----\n",
    "encoder_gru = GRU(LATENT_DIM, return_sequences=True, return_state=True)\n",
    "encoder_outputs_gru, state_h_gru = encoder_gru(enc_emb)\n",
    "\n",
    "# ----- Decoder -----\n",
    "decoder_gru = GRU(LATENT_DIM, return_sequences=True, return_state=True)\n",
    "decoder_outputs_gru, _ = decoder_gru(dec_emb, initial_state=[state_h_gru])\n",
    "\n",
    "# ----- Attention -----\n",
    "attn_gru = Attention()\n",
    "attn_out_gru = attn_gru([decoder_outputs_gru, encoder_outputs_gru])\n",
    "\n",
    "decoder_concat_gru = Concatenate(axis=-1)([decoder_outputs_gru, attn_out_gru])\n",
    "\n",
    "# ----- Output -----\n",
    "outputs_gru = Dense(tgt_vocab, activation=\"softmax\")(decoder_concat_gru)\n",
    "\n",
    "# ----- Final Model -----\n",
    "gru_model = Model([encoder_inputs, decoder_inputs], outputs_gru)\n",
    "\n",
    "gru_model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "gru_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b1c102a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m 108/1599\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m28:10\u001b[0m 1s/step - accuracy: 0.1250 - loss: 7.1320"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 12\u001b[0m\n\u001b[0;32m      3\u001b[0m X_train, X_val, Y_train_in, Y_val_in, Y_train_out, Y_val_out \u001b[38;5;241m=\u001b[39m train_test_split(\n\u001b[0;32m      4\u001b[0m     enc_seq,\n\u001b[0;32m      5\u001b[0m     dec_in_seq,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      8\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m\n\u001b[0;32m      9\u001b[0m )\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# ----- Train LSTM -----\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[43mlstm_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train_in\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mY_train_out\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_val_in\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_val_out\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce_lr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_lstm\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# ----- Train GRU -----\u001b[39;00m\n\u001b[0;32m     22\u001b[0m gru_model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m     23\u001b[0m     [X_train, Y_train_in],\n\u001b[0;32m     24\u001b[0m     Y_train_out,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     28\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[early_stop, reduce_lr, ckpt_lstm]\n\u001b[0;32m     29\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\miniconda3\\envs\\ml_env\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\miniconda3\\envs\\ml_env\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:399\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    397\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m begin_step, end_step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[0;32m    398\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(begin_step)\n\u001b[1;32m--> 399\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    400\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(end_step, logs)\n\u001b[0;32m    401\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\miniconda3\\envs\\ml_env\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:241\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfunction\u001b[39m(iterator):\n\u001b[0;32m    238\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m    239\u001b[0m         iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[0;32m    240\u001b[0m     ):\n\u001b[1;32m--> 241\u001b[0m         opt_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    242\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[0;32m    243\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\miniconda3\\envs\\ml_env\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\miniconda3\\envs\\ml_env\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\miniconda3\\envs\\ml_env\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\miniconda3\\envs\\ml_env\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\miniconda3\\envs\\ml_env\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\miniconda3\\envs\\ml_env\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\miniconda3\\envs\\ml_env\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\miniconda3\\envs\\ml_env\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:1688\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1686\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1688\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1689\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1690\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1691\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1692\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1693\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1694\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1695\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1696\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1697\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1698\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1702\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1703\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\miniconda3\\envs\\ml_env\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, Y_train_in, Y_val_in, Y_train_out, Y_val_out = train_test_split(\n",
    "    enc_seq,\n",
    "    dec_in_seq,\n",
    "    dec_out_seq,\n",
    "    test_size=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# ----- Train LSTM -----\n",
    "lstm_model.fit(\n",
    "    [X_train, Y_train_in],\n",
    "    Y_train_out,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=5,\n",
    "    validation_data=([X_val, Y_val_in], Y_val_out),\n",
    "    callbacks=[early_stop, reduce_lr, ckpt_lstm]\n",
    ")\n",
    "\n",
    "# ----- Train GRU -----\n",
    "gru_model.fit(\n",
    "    [X_train, Y_train_in],\n",
    "    Y_train_out,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=5,\n",
    "    validation_data=([X_val, Y_val_in], Y_val_out),\n",
    "    callbacks=[early_stop, reduce_lr, ckpt_lstm]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
